{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970c745a",
   "metadata": {},
   "source": [
    "# Importing and Revising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede89e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "import numpy             as np                       # numpy, data science essencial\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "\n",
    "# loading data\n",
    "file = \"./GOT_character_predictions.xlsx\"\n",
    "GOT = pd.read_excel(io=file)\n",
    "\n",
    "# displaying the head of the dataset\n",
    "GOT.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf183d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT2 = pd.DataFrame.copy(GOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e82d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "print(GOT2.isnull().any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# spliting names \n",
    "for row, col in GOT2.iterrows():\n",
    "    \n",
    "    # splitting name by space\n",
    "    split_name = GOT2.loc[row, 'name'].split(sep = ' ')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_name)\n",
    "    \n",
    "\n",
    "# converting into a DataFrame \n",
    "name_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "#renaming the columns \n",
    "name_df.columns = ['f_name' , 'last_name', 'last_name_2','name4', 'name5', 'name6']\n",
    "#concatening the name \n",
    "\n",
    "GOT2 = pd.concat([GOT2, name_df['f_name']],\n",
    "                     axis = 1)\n",
    "GOT2 = pd.concat([GOT2, name_df['last_name']],\n",
    "                     axis = 1)\n",
    "GOT2 = pd.concat([GOT2, name_df['last_name_2']],\n",
    "                     axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing gender based on (given) name\n",
    "# placeholder list\n",
    "#placeholder_lst_2 = []\n",
    "\n",
    "\n",
    "# looping to guess gender\n",
    "#for name in GOT2['f_name']:\n",
    "    #guess = gender.Detector().get_gender(name)\n",
    "    #placeholder_lst_2.append(guess)\n",
    "\n",
    "#print(placeholder_lst_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list into a series\n",
    "GOT2['gender'] = pd.Series(['unknown', 'unknown', 'andy', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'andy', 'andy', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'mostly_male', 'male', 'mostly_male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'female', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'andy', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'female', 'female', 'female', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'mostly_female', 'female', 'unknown', 'mostly_female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'female', 'male', 'male', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'andy', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'male', 'male', 'male', 'unknown', 'female', 'female', 'female', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'female', 'male', 'female', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'male', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'female', 'mostly_female', 'female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'mostly_female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'mostly_male', 'unknown', 'female', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'female', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'andy', 'male', 'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', 'mostly_male', 'mostly_male', 'mostly_male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'male', 'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5becd",
   "metadata": {},
   "source": [
    "# Generating and Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cf74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT3 = pd.DataFrame.copy(GOT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402c562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GOT3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT3.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing missing values\n",
    "age_mead = GOT3 ['age'].median()\n",
    "GOT3['age'].fillna(value = age_mead,\n",
    "                       inplace = True)\n",
    "date_mead = GOT2 ['dateOfBirth'].median()\n",
    "GOT3['dateOfBirth'].fillna(value = date_mead,\n",
    "                       inplace = True)\n",
    "GOT3['title'].fillna(value = 'unknown',\n",
    "                       inplace = True)\n",
    "GOT3['mother'].fillna(value = 'unknown',\n",
    "                       inplace = True)\n",
    "GOT3['father'].fillna(value = 'unknown',\n",
    "                       inplace = True)\n",
    "GOT3['father'].fillna(value = 'unknown',\n",
    "                       inplace = True)\n",
    "GOT3['heir'].fillna(value = 'none',\n",
    "                       inplace = True)\n",
    "GOT3['spouse'].fillna(value = 'none',\n",
    "                       inplace = True)\n",
    "GOT3['isAliveMother'].fillna(value = 0,\n",
    "                       inplace = True)\n",
    "GOT3['isAliveFather'].fillna(value = 0,\n",
    "                       inplace = True)\n",
    "GOT3['isAliveHeir'].fillna(value = 0,\n",
    "                       inplace = True)\n",
    "GOT3['isAliveSpouse'].fillna(value = 0,\n",
    "                       inplace = True)\n",
    "GOT3['isMarried'].fillna(value = 0,\n",
    "                       inplace = True)\n",
    "GOT3['isNoble'].fillna(value = 0,\n",
    "                       inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b96c87d",
   "metadata": {},
   "source": [
    "I just Filled the values, the ones like title, mother, father, heir,  I assumed this information os unknoown, which is the value i filled them with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f4ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, col in GOT3.iterrows():\n",
    "    if GOT3.loc[index,'gender']=='mostly_female':\n",
    "        GOT3.loc[index,'gender']='female'\n",
    "    elif GOT3.loc[index,'gender']== 'mostly_male':\n",
    "        GOT3.loc[index,'gender'] = 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21140658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(GOT3['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating new columns \n",
    "\n",
    "GOT3['dateOfDeath'] = GOT3['dateOfBirth']+GOT3['age']\n",
    "dummy_gender = pd.get_dummies(GOT3['gender'])\n",
    "GOT3 = GOT3.join([dummy_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4005f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GOT3.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85711b",
   "metadata": {},
   "source": [
    "In the next part I'll determine the house of a character by using their last name, so i used the first last name and the second, in order to actually catch the last name, I also thought that  by only using the important houses I might positively impact the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1785962",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating another column with houses \n",
    "\n",
    "GOT3['House_1']=0\n",
    "\n",
    "for row, col in GOT3.iterrows():\n",
    "    if GOT3.loc[row,'last_name']=='Lannister' or GOT3.loc[row,'last_name_2']=='Lannister':\n",
    "        GOT3.loc[row,'House_1']='Lannister'\n",
    "        \n",
    "    elif GOT3.loc[row,'last_name']=='Targaryen' or GOT3.loc[row,'last_name_2']=='Targaryen':\n",
    "        GOT3.loc[row,'House_1']='Targaryen' \n",
    "        \n",
    "    elif GOT3.loc[row,'last_name']=='Baratheon' or GOT3.loc[row,'last_name_2']=='Baratheon':\n",
    "        GOT3.loc[row,'House_1']='Baratheon'\n",
    "    \n",
    "    elif GOT3.loc[row,'last_name']=='Stark' or GOT3.loc[row,'last_name_2']=='Stark':\n",
    "        GOT3.loc[row,'House_1']='Stark'\n",
    "        \n",
    "    elif GOT3.loc[row,'last_name']=='Tyrell' or GOT3.loc[row,'last_name_2']=='Tyrell':\n",
    "        GOT3.loc[row,'House_1']='Tyrell'\n",
    "        \n",
    "    elif GOT3.loc[row,'last_name']=='Arryn' or GOT3.loc[row,'last_name_2']=='Arryn':\n",
    "        GOT3.loc[row,'House_1']='Arryn'\n",
    "        \n",
    "    elif GOT3.loc[row,'last_name']=='Greyjoy' or GOT3.loc[row,'last_name_2']=='Greyjoy':\n",
    "        GOT3.loc[row,'House_1']='Greyjoy'\n",
    "        \n",
    "    else:\n",
    "        GOT3.loc[row,'House_1']='Other'\n",
    "        \n",
    "\n",
    "GOT3['House_1'].head(n=5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_gender = pd.get_dummies(GOT3['House_1'])\n",
    "GOT3 = GOT3.join([dummy_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdede59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column for has_title\n",
    "\n",
    "GOT3['has_title']=0\n",
    "for row,col in GOT3.iterrows():\n",
    "    if GOT3.loc[row,'title'] == 'unknown':\n",
    "        GOT3.loc[row,'has_title']= 0\n",
    "    elif GOT3.loc[row,'title'] != 'unknown':\n",
    "        GOT3.loc[row,'has_title'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT_corr = GOT3.corr(method = 'pearson').round(decimals = 2)\n",
    "GOT_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad393551",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT3.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9e13e",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13644175",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT3.loc[ : ,'isAlive'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdf6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "GOT_data = GOT3.loc[ : , ['dateOfDeath','book4_A_Feast_For_Crows', 'Targaryen','book1_A_Game_Of_Thrones']]\n",
    "GOT_target = GOT3.loc[ : , 'isAlive']\n",
    "\n",
    "# this is the exact   code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data,\n",
    "            GOT_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eec460",
   "metadata": {},
   "source": [
    "# Classification Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3965947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc\n",
    "full_tree_gap = abs(full_tree_train_score - full_tree_test_score).round(4)\n",
    "\n",
    "print('Full Tree Train-Test Gap   :', abs(full_tree_train_score - full_tree_test_score).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47401f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc\n",
    "pruned_tree_gap = abs(pruned_tree_train_score - pruned_tree_test_score).round(4)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "print('pruned Tree Train-Test Gap   :', abs(pruned_tree_train_score - pruned_tree_test_score).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcafe16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268a470",
   "metadata": {},
   "source": [
    "# KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555dab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3c663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(x_data        = GOT_data,\n",
    "                                  y_data        = GOT_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33ddfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(GOT_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(GOT_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            GOT_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "print('KNN Train-Test Gap   :', abs(knn_train_score - knn_test_score).round(4))\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)\n",
    "\n",
    "Knn_gap = abs(knn_train_score - knn_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a778d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tn, \\\n",
    "knn_fp, \\\n",
    "knn_fn, \\\n",
    "knn_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tn}\n",
    "False Positives: {knn_fp}\n",
    "False Negatives: {knn_fn}\n",
    "True Positives : {knn_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d5f14",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 4,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)\n",
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "rf_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "rf_gap = abs(rf_train_acc - rf_test_acc).round(4)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "print('pruned Tree Train-Test Gap   :', abs(rf_train_acc - rf_test_acc).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6efc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafe451",
   "metadata": {},
   "source": [
    "# Hiperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e351524d",
   "metadata": {},
   "source": [
    "## Full tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "# criterion_range = ['gini', 'entropy']\n",
    "# splitter_range  = ['best', 'random']\n",
    "# depth_range     = np.arange(1, 8, 1)\n",
    "# leaf_range      = np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion'        : criterion_range,\n",
    "#               'splitter'         : splitter_range,\n",
    "#               'max_depth'        : depth_range,\n",
    "#               'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # RandomizedSearchCV object\n",
    "# tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                    param_distributions   = param_grid,\n",
    "#                                    cv                    = 3,\n",
    "#                                    n_iter                = 1000,\n",
    "#                                    random_state          = 219,\n",
    "#                                    scoring = make_scorer(roc_auc_score,\n",
    "#                                              needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# tuned_tree_cv.fit(GOT_data, GOT_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0320ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(splitter         = 'best',\n",
    "                                    min_samples_leaf = 3,\n",
    "                                    max_depth        = 7,\n",
    "                                    criterion        = 'entropy',\n",
    "                                    random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tree_tuned_fit = tree_tuned.fit(GOT_data, GOT_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                       y_score = tree_tuned_pred).round(4) # auc\n",
    "tree_tuned_gap =  abs(tree_tuned_train_score - tree_tuned_test_score).round(4)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "print('Gap       :', abs(tree_tuned_train_score - tree_tuned_test_score).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be92ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_tn, \\\n",
    "tt_fp, \\\n",
    "tt_fn, \\\n",
    "tt_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tt_tn}\n",
    "False Positives: {tt_fp}\n",
    "False Negatives: {tt_fn}\n",
    "True Positives : {tt_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83efb4",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c88ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FITTING the training data\n",
    "# rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# estimator_range  = np.arange(100, 2000, 250)\n",
    "# leaf_range       = np.arange(1, 31, 10)\n",
    "# criterion_range  = ['gini', 'entropy']\n",
    "# bootstrap_range  = [True, False]\n",
    "# warm_start_range = [True, False]\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'n_estimators'     : estimator_range,\n",
    "#               'min_samples_leaf' : leaf_range,\n",
    "#               'criterion'        : criterion_range,\n",
    "#               'bootstrap'        : bootstrap_range,\n",
    "#               'warm_start'       : warm_start_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                                param_distributions = param_grid,\n",
    "#                                cv         = 3,\n",
    "#                                n_iter     = 1000,\n",
    "#                                scoring    = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# forest_cv.fit(GOT_data, GOT_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df83343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_tuned = RandomForestClassifier(n_estimators     = 350,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 4,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = True,\n",
    "                                    random_state     = 219)\n",
    "# FITTING the training data\n",
    "rf_tuned_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_tuned_fit_pred = rf_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "rf_tuned_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_tuned_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_tuned_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "rf_tuned_gap = abs(rf_train_acc - rf_test_acc).round(4)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "print('pruned Tree Train-Test Gap   :', abs(rf_train_acc - rf_test_acc).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50061ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_tn, \\\n",
    "trf_fp, \\\n",
    "trf_fn, \\\n",
    "trf_tp = confusion_matrix(y_true = y_test, y_pred = rf_tuned_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {trf_tn}\n",
    "False Positives: {trf_fp}\n",
    "False Negatives: {trf_fn}\n",
    "True Positives : {trf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac900c",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Model                       Auc Score      Gap        TN    FP     FN      TP\n",
    "-----                      -----------  ----------   -----  ----   ----    ----\n",
    "Log_regg             /      {logreg_auc_score}         {logreg_test_gap}      {logreg_tn}     {logreg_fp}      {logreg_fn}    {logreg_tp}   \n",
    "Full Tree            /      {full_tree_auc_score}            {full_tree_gap}    {full_tree_tn}      {full_tree_fp}     {full_tree_fp}    {full_tree_tp}\n",
    "Pruned Tree          /      {pruned_tree_auc_score}          {pruned_tree_gap}     {pruned_tree_tn}     {pruned_tree_fp}    {pruned_tree_fp}    {pruned_tree_tp}\n",
    "KNN                  /      {knn_auc_score}          {Knn_gap}     {knn_tn}     {knn_fp}      {knn_fn}      {knn_tp}\n",
    "Random Forest        /      {rf_auc}           {rf_gap}      {rf_tn}    {rf_fp}      {rf_fn}     {rf_tp}\n",
    "Tuned Pruned Tree    /      {tree_tuned_auc}          {tree_tuned_gap}      {tt_tn}    {tt_fp}      {tt_fn}     {tt_tp}\n",
    "Tuned Random Forest  /      {rf_tuned_auc}           {rf_tuned_gap}      {trf_tn}    {trf_fp}      {trf_fn}     {trf_tp}\n",
    "\"\"\")\n",
    "\n",
    "print(\"***Model to use : Tuned Pruned Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOT_data = GOT3.loc[ : , ['dateOfDeath','book4_A_Feast_For_Crows', 'popularity' , 'book1_A_Game_Of_Thrones']] AUC= 73.97\n",
    "#GOT_data = GOT3.loc[ : , ['dateOfDeath','book4_A_Feast_For_Crows', 'Targaryen','book1_A_Game_Of_Thrones']] AUC=74.6\n",
    "#GOT_data = GOT3.loc[ : , ['dateOfDeath','book4_A_Feast_For_Crows', 'popularity','book1_A_Game_Of_Thrones','numDeadRelations','Targaryen']] AUC = 77.9\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
